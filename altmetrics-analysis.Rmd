---
geometry: margin=1.5in
output:
  pdf_document:
    fig_caption: yes
---
```{r eval = FALSE, echo=FALSE, message=FALSE, warning=FALSE}
fig.height = 2.5
fig.width = 1.5 * fig.height
font_size = 8

knitr::opts_chunk$set(fig.height = fig.height, fig.width = fig.width, 
					  echo = FALSE, message=FALSE, warning=FALSE)

```

## Results ##

```{r, eval = FALSE}
## Run the Python scripts with the Altmetrics queries
system2('python3', args = 'publications\\ data/scrape.py')
```

```{r setup_analysis, cache = FALSE} 
library(cowplot)
	ggplot2::theme_set(cowplot::theme_cowplot(font_size = font_size))
library(dplyr)
library(knitr)
library(lubridate)
library(rjson)
library(xtable)

## Load all of the DOIs, even the ones that weren't in Altmetrics
infiles = 'publications data/scraped pubs/combined dois.json'
all_dois <- c()
for (infile in infiles) {
	all_dois <- c(all_dois, fromJSON(file = infile))
}
all_dois <- unique(all_dois)

## Load data, with mutations for R data types
folder = 'publications data/twitter/'
papers <- read.csv(paste(folder, 'metadata.csv', sep = ''), 
				   stringsAsFactors = FALSE) %>%
		mutate(n_tweets = as.integer(ifelse(is.na(n_tweets), 0, n_tweets)), 
			   first_seen = ymd_hms(first_seen), 
			   published = ymd_hms(published), 
			   year = floor_date(published, unit = 'year'))
tweets <- read.csv(paste(folder, 'tweets.csv', sep = '')) %>%
		mutate(timestamp = ymd_hms(timestamp))
tweeters <- read.csv(paste(folder, 'tweeters.csv', sep = ''))
```

A total of `r length(all_dois)` DOIs for CSS publications were identified.  Altmetrics returned responses for `r nrow(papers)` of these DOIs, of which 
`r {papers %>% filter(n_tweets > 0) %>% nrow}` 
(`r (1-ecdf(papers$n_tweets)(0))*100`%) 
had 1 or more tweets, for a total of `r nrow(tweets)` tweets.  `r {papers %>% filter(n_tweets >= 10) %>% nrow}` papers had 10 or more tweets; see figure \ref{fig.n_tweets}A and table \ref{tab.high_tweet_papers}.  There is considerable variation in the number of tweets over time; see figure \ref{fig.n_tweets}B.  Tweets are made in `r tweets$account_loc %>% unique %>% length` different countries, though `r {tweets %>% filter(account_loc == '') %>% nrow} / nrow(tweets) * 100`% have no country information; see figure \ref{fig.countries}.  

```{r fig.width = 2*fig.width, fig.cap = 'Number of tweets.  \\textbf{A}: Histogram of tweets per paper.  \\textbf{B}: Number of tweets per month. \\label{fig.n_tweets}'}
## Histogram of tweets per paper
tweets_paper_hist = ggplot(data = papers, aes(x = n_tweets)) + 
	geom_bar(fill = 'blue') + 
	scale_x_log10(name = 'no. tweets', breaks = c(1, seq(10, 100, 20))) +
	ylab('no. papers')
## Scatterplot of n tweets vs. year
# ggplot(data = papers, aes(x = year, y = n_tweets)) + 
# 	geom_point()
## Plot tweets over time
tweets <- tweets %>% mutate(month = round_date(timestamp, unit = 'month'))
tweets_month = ggplot(data = tweets, aes(x = month)) + 
	#geom_line(stat = 'count', color = 'red') +
	geom_bar(fill = 'red') +
	geom_hline(yintercept = 0) +
	theme(axis.text.x=element_text(angle = 30, hjust = 1)) +
	ylab('no. tweets')
plot_grid(tweets_paper_hist, tweets_month, labels = 'AUTO')
```

```{r high_tweet_papers, results = 'asis'}
## List of relatively highly-tweeted papers
papers %>% filter(n_tweets >= 10) %>% transmute(DOI = doi, title = title, `no. tweets` = n_tweets) %>%
	arrange(desc(`no. tweets`)) %>% 
	xtable(align = 'llp{3in}r', 
		   caption = 'Highly-tweeted papers', 
		  label = 'tab.high_tweet_papers') %>% 
	print(include.rownames = FALSE, comment = FALSE)
```

```{r eval = FALSE}
## Table of countries with number of tweets and percentage of all tweets
tweets %>% group_by(account_loc) %>% 
	summarize(n_tweets = n()) %>% 
	mutate(tot_tweets = sum(n_tweets), perc_tweets = n_tweets / tot_tweets * 100) %>%
	arrange(desc(perc_tweets))
```
```{r fig.cap = 'Number of tweets per country, countries with at least 5 tweets \\label{fig.countries}'}
## Histogram of countries with at least 5 tweets
ggplot(data = {tweets %>% group_by(account_loc) %>% 
		summarize(n_tweets = n()) %>%
		mutate(country = reorder(account_loc, n_tweets)) %>%
		filter(n_tweets >= 5, account_loc != '')}, 
		aes(x = country, y = n_tweets, fill = country)) +
	geom_bar(stat = 'identity') +
	scale_fill_discrete(guide = FALSE) +
	ylab('no. tweets') +
	coord_flip()
## Tweets over time, by location
##  Needs filters to be useful! 
#ggplot(data = tweets, aes(x = month, color = account_loc)) + geom_line(stat = 'count')
```

The `r sum(tweeters$n_tweets)` were made by `r nrow(tweeters)` distinct accounts.  `r {tweeters %>% filter(n_tweets == 1) %>% nrow}` accounts (`r ecdf(tweeters$n_tweets)(2) * 100`%) made only a single tweet of a CSS paper, while `r {tweeters %>% filter(n_tweets >= 5) %>% nrow}` accounts made 5 or more tweets; see figure \ref{fig.accounts_hist} and table \ref{tab.high_tweeters}.  Many of these relatively high-tweeting accounts promote recent publications in a scientific topic, in a journal, or of potential interest to members of a professional society.  

```{r fig.cap = 'Histogram of tweets per account \\label{fig.accounts_hist}'}
## Histogram of tweeters
ggplot(data = tweeters, aes(x = n_tweets)) + geom_bar() +
	scale_x_log10(breaks=c(1, seq(2, 18, by = 2)), name = 'no. tweets') +
	ylab('no. accounts')
```

```{r}
## List of relatively high number of tweeters
tweeters %>% filter(n_tweets >= 5) %>% 
	select(account, n_tweets, n_followers, location) %>%
	arrange(desc(n_tweets)) %>% 
	kable(col.names = c('account', 'no. tweets', 'no. followers', 'location'),
		  format = 'latex',
		  caption = 'Twitter accounts producing more than 5 tweets of CSS publications \\label{tab.high_tweeters}')
```


### Reach ###

In marketing, *reach* refers to the size of the potential audience.  The Altmetrics API provides the number of followers at the time of each individual tweet.  These follower counts can be used to estimate reach at the paper level and over time.  (Note that the followers for two given tweets can overlap, and so these are likely to be overestimates.)  Aggregated both ways, reach varies over more than two orders of magnitude.  See figure \ref{fig.reach}. 

```{r fig.width = 2*fig.width, fig.cap = 'Kernel density estimates of estimated reach. \\textbf{A}: Reach per paper. \\textbf{B}: Reach per month. \\label{fig.reach}'}
## Estimate reach per paper
reach_by_paper <- tweets %>% group_by(paper_doi) %>% 
						summarize(reach = sum(account_followers))
## Kernel density estimate plot
reach_paper_kde = ggplot(data = reach_by_paper, aes(x = reach)) + 
	geom_density() +
	scale_x_log10(breaks = 10^(0:5))
## ECDF plot
# ggplot(data = reach_by_paper, aes(x = reach)) + stat_ecdf() +
# 	scale_x_log10(breaks = 10^(0:5))

## Estimate reach per month
reach_by_month <- tweets %>% group_by(month) %>%
						summarize(reach = sum(account_followers))
## Kernel density estimate plot
reach_month_kde = ggplot(data = reach_by_month, aes(x = reach)) + 
	geom_density() +
	scale_x_log10(breaks = 10^(0:5))
## ECDF plot
# ggplot(data = reach_by_month, aes(x = reach)) + stat_ecdf() + 
# 	scale_x_log10(breaks = 10^(0:5))
plot_grid(reach_paper_kde, reach_month_kde, labels = 'AUTO')
```

```{r eval = FALSE}
## Reach by month, plotted over time
ggplot(data = reach_by_month, aes(x = month, y = reach)) +
	#geom_line(color = 'red') +
	geom_bar(fill = 'blue', stat = 'identity', position = 'identity') +
	geom_hline(yintercept = 0) +
	scale_y_log10(breaks = 10^(0:5)) +
	theme(axis.text.x=element_text(angle = 30, hjust = 1))
```


### Delay and Lifespan ###

```{r}
## Identify the earliest and latest tweet for each paper
##  and calculate delay and lifespan
papers <- left_join(papers, 
				  {tweets %>% group_by(paper_doi) %>% 
				  		summarize(first_tweet = min(timestamp), 
				  				  last_tweet = max(timestamp))}, 
				  by = c('doi' = 'paper_doi')) %>%
				mutate(delay = difftime(first_tweet, published, 
										units = 'days'),
					   lifespan = difftime(last_tweet, first_tweet, 
					   					units = 'days')
					   )
```

*Delay* can be defined as the time between publication date (as recorded in the Altmetrics metadata) and the first tweet.  Delay had a mean of `r mean(papers$delay, na.rm = T)` days and median of `r median(papers$delay, na.rm = T)` days, with an interquartile range of `r IQR(papers$delay, na.rm = T)` days.  `r ecdf(papers$delay)(7) * 100`% of papers had a delay of less than 7 days; notably, `r ecdf(papers$delay)(0) * 100`% of papers had a negative delay, indicating that the paper was first tweeted before it was officially published.  No relationship was identified between delay and the total number of tweets received by a paper.  See figure \ref{fig.delay} and table \ref{tab.delay}.  

```{r delay_plot, fig.width = 1.5 * fig.width, fig.cap = 'Delay. \\textbf{A}: Kernel density estimate of delay. \\textbf{B} and \\textbf{C}: Scatterplot of the total number of tweets vs. delay.  Grey rectangles in the two plots correspond.  Blue line is a linear regression for the entire dataset.\\label{fig.delay}'}
## KDE of delay
delay_kde = ggplot(data = papers, aes(x = delay)) + 
	geom_density(alpha = .5, position = 'stack') +
	geom_rug() +
	xlab('delay (days)')
	#coord_cartesian(xlim = c(0, 28))

## Number of tweets vs. delay
xmin <- -5*7; xmax <- 15*7; ymin <- 0; ymax <- 20
tweets_delay_plot <- ggplot(data = papers,
							aes(x = delay, y = n_tweets)) +
	geom_point(position = 'jitter') +
	geom_rect(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, 
				  fill = NA, linetype = 'dashed', color = 'gray', 
				  alpha = .05) +
	xlab('delay (days)') + ylab('no. tweets')
tweets_delay_all <- tweets_delay_plot + 
		stat_smooth(method = 'lm', alpha = .1) +
		coord_cartesian(ylim = c(0, 80))
tweets_delay_zoom <- tweets_delay_plot + 
	stat_smooth(method = 'lm', alpha = .1) + 
	coord_cartesian(xlim = c(xmin, xmax), ylim = c(ymin, ymax))
#tweets_delay_all; tweets_delay_zoom
tweets_delay_comb = plot_grid(tweets_delay_all, tweets_delay_zoom, 
							  labels = c('B', 'C'))
plot_grid(delay_kde, tweets_delay_comb, nrow = 2, labels = c('A', NA))
```

```{r delay_table}
## There's no evidence of a relationship here
#lm(data = papers, n_tweets ~ delay) %>% summary

## Table of week vs. percentile
data.frame(week = seq(0, 4)) %>% 
	mutate(percentile = ecdf(papers$delay)(week*7)*100) %>%
	kable(format = 'latex', 
		  caption = 'Delay, cumulative percentiles, by week \\label{tab.delay}')
## Table of percentile vs. day
# data.frame(decimal = seq(.10, .90, by = .10)) %>%
# 	transmute(percentile = decimal * 100, 
# 				days = as.numeric(quantile(papers$delay, 
# 									  probs = decimal, na.rm = TRUE))) %>%
# 	kable
```

Similarly, *lifespan* can be defined as the time between the first and last tweet.  Lifespan had a mean of `r mean(papers$lifespan, na.rm = T)` days and median of `r median(papers$lifespan, na.rm = T)*24` *hours*, with an interquartile range of `r IQR(papers$lifespan, na.rm = T)` days.  `r ecdf(papers$lifespan)(7) * 100`% of papers had a lifespan of less than 7 days. Note that `r papers %>% filter(lifespan == 0) %>% nrow` papers received only a single tweet, and thus had a lifespan of 0; excluding these papers, mean lifespan is 
`r papers %>% filter(lifespan > 0) %>% .[['lifespan']] %>% mean(na.rm = T)` days and median lifespan is 
`r papers %>% filter(lifespan > 0) %>% .[['lifespan']] %>% median(na.rm = T)` days.  See figure \ref{fig.span} and table \ref{tab.span}. 

```{r lifespan_plot, fig.width = 1.5 * fig.width, fig.cap = 'Lifespan, time between first and last tweet. \\textbf{A}: Kernel density estimate of lifespan \\textbf{B} and \\textbf{C}: Scatterplot of the total number of tweets vs. lifespan.  Grey rectangles in the two plots correspond.  Blue line is a linear regression for the entire dataset. \\label{fig.span}'}
## KDE of lifespan
lifespan_kde = ggplot(data = papers, aes(x = lifespan)) + 
	geom_density(alpha = .5, position = 'stack') +
	geom_rug() +
	xlab('lifespan (days)')
#	coord_cartesian(xlim = c(0, 100)) + 

## Number of tweets vs. lifespan
xmin <- 0; xmax <- 50*7; ymin <- 0; ymax <- 20
tweets_span_plot <- ggplot(data = papers,
							aes(x = lifespan, y = n_tweets)) +
		geom_point(position = 'jitter') +
		geom_rect(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, 
				  fill = NA, linetype = 'dashed', color = 'gray', 
				  alpha = .05) + 
		xlab('lifespan (days)') + ylab('no. tweets')
tweets_span_all <- tweets_span_plot + 
		stat_smooth(method = 'lm', alpha = .1)
tweets_span_zoom <- tweets_span_plot + 
	stat_smooth(method = 'lm', alpha = .1) + 
	coord_cartesian(xlim = c(xmin, xmax), ylim = c(ymin, ymax))
tweets_span_comb = plot_grid(tweets_span_all, tweets_span_zoom, 
	labels = c('B', 'C'))
plot_grid(lifespan_kde, tweets_span_comb, nrow = 2, labels = c('A', NA))
```

```{r lifespan_table}
## There's no evidence of a relationship here, either
#lm(data = papers, n_tweets ~ lifespan) %>% summary

## Cumulative percentile tables
data.frame(week = seq(0, 14, by = 2)) %>% 
	mutate(percentile = ecdf(papers$lifespan)(week*7) * 100) %>%
	kable(format = 'latex',
		  caption = 'Lifespan, cumulative percentiles, by week 
		  				\\label{tab.span}')
# data.frame(decimal = seq(.10, .90, by = .20)) %>%
# 	transmute(percentile = decimal * 100, 
# 			  days = as.numeric(quantile(papers$lifespan, 
# 			  						   probs = decimal, na.rm = TRUE))) %>%
# 	kable
```

Finally, there is no observed relationship between delay and lifespan.  See figure \ref{fig.delay_span}.  

```{r delay_span, fig.width = 1.5 * fig.width, fig.cap = 'Scatterplot of lifespan vs. delay.  Grey rectangles in A and B correspond.  Blue line is a linear regression of the entire dataset. \\label{fig.delay_span}'}
## Delay vs. lifespan
xmin <- 0; xmax <- 52*7; ymin <- 0; ymax <- 52*7
delay_span_plot <- ggplot(data = papers, aes(delay, lifespan)) + 
		geom_point(position = 'jitter') +
		geom_rect(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, 
				  fill = NA, linetype = 'dashed', color = 'gray', 
				  alpha = .05) + 
		stat_smooth(method = 'lm') + 
	coord_cartesian(ylim = c(0, max(papers$lifespan, na.rm = TRUE)))
delay_span_all <- delay_span_plot
delay_span_zoom <- delay_span_plot + 
	coord_cartesian(xlim = c(xmin, xmax), ylim = c(ymin, ymax))
plot_grid(delay_span_all, delay_span_zoom, labels = 'AUTO')
#lm(data = papers, as.numeric(lifespan) ~ as.numeric(delay)) %>% summary
```









