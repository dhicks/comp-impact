---
output: 
    pdf_document:
        fig_caption: true
---
```{r eval = FALSE}
fig.height = 3
font_size = 10
```

# Study 1: Altmetrics #

The term "altmetrics" has two distinct meanings.  Small-a "altmetrics" is a portmanteau of "alternative bibliometrics," that is, alternatives to such metrics as paper citation counts, journal impact factors, and researcher H-indices.  These standard bibliometrics are designed to measure the impact of research within the scholarly community, and thus are generally not useful for assessing social impacts.  Consequently, there is a substantial amount of active work on developing altmetrics that are relevant to social impact.  *[cite Britt etc.]*

Large-a "Altmetrics" refers to "Altmetric.com," a UK-based company that develops an integrated set of small-a altmetrics and makes them available programmatically using a web-based API [application programming interface].  Large-a Altmetrics focuses on social media references to research publications, such as tweets and blog posts.  The analysis explored here uses Altmetrics' tweets data to examine the social media impact of CSS publications.  

## Data ##

Bibliometrics, like other opportunistic uses of independently-cultivated data, depends on stable identifiers that can track individual research targets — such as research publications — across datasets from multiple sources.  DOI, or the digital object identifier, has emerged as a major standard identifier for research publications.  Other identifiers, such as PubMed's internal identifier, are common, but not as widely-used as DOI *[ref]*.  Altmetrics' API accepts queries in terms of both DOIs and PubMed IDs.  

The first step in any bibliometrics analysis, then, is determining the DOI for each publication of interest.  For an analysis of CSS publications, ideally, these DOIs could be identified along with the publications of interest, by searching a database that (a) includes DOIs in the publication metadata, (b) permits a search by EPA research program, and (c) can export machine-readable search results.  As far as I have been able to tell, EPA does not have any general publications database that satisfies all three desiderata.  The "public-facing" version of Science Inventory (<https://cfpub.epa.gov/si/>; note that this site is not accessible outside of the EPA firewall) does not appear to satisfy any of these three requirements. The "internal application" version of Science Inventory (<https://cfext.epa.gov/si/SciInv/stmProtoLogin.cfm>) requires a separate registration for access; when I attempted to register a new account, the system generated errors that could not be resolved.  

STICS [Science and Technical Information Clearance System] is designed to support the clearance and approval of research products before they are submitted to a journal for publication.  STICS satisfies criteria (b) and (c), and thus can export a list of all research products associated with CSS.  However, presumably because it is designed for use only pre-publication, STICS does not include DOIs. 
After examining the metadata outputs from STICS, I decided that the most efficient way to identify DOIs corresponding to STICS records would be to search for matching titles in Scopus, a large database of research publications similar to Web of Science or PubMed.  Python scripts were prepared to conduct both "quoted" and "unquoted" searches for each research product title.  A quoted search searches for the title as a complete phrase; for example, a quoted search for the title "Recent Work in High-Throughput Toxicology" would not match "Recent Work for High-Throughput Toxicology."  An unquoted search matches the individual terms; for example, "Recent Work in High-Throughput Toxicology" *would* match with "Recent Work for High-Throughput Toxicology" (assuming that the search system ignored very common words such as "for" and "in").  An unquoted search is useful for catching publications for which the title had been changed sometime during the review process, or for handling encoding errors, as in the title "A Framework for &quot;Fit for Purpose&quot; Dose Response Assessment"; however, an unquoted search is obviously more likely to return incorrect matches.  

In what follows, the results of these searches are compared with two manually-curated databases of publications:  an EndNote database sporadically updated by CSS staff and a database of NCCT publications curated by Monica Linnenbrink.  Both of the latter two databases include DOIs, but neither is intended to be a comprehensive collection of all CSS publications.  

*[call Python scripts to build `scraped pubs` files]*

```{r setup_data}
library(cowplot)
	theme_set(theme_cowplot(font_size = 10))
library(dplyr)
library(knitr)
library(rjson)
library(reshape2)

folder = 'publications data/scraped pubs/'

ids_css = fromJSON(file = paste(folder, 'ids_css.json', sep = '')) %>% unique
ids_css = data.frame(doi = ids_css, endnote = TRUE, stringsAsFactors = FALSE)
## Replace some mis-stored DOIs
ids_css$doi = gsub('doi:', '', ids_css$doi)
ids_css$doi = gsub('http://dx.doi.org/', '', ids_css$doi)

ids_ncct = fromJSON(file = paste(folder, 'ids_ncct.json', sep = '')) %>% unique
ids_ncct = data.frame(doi = ids_ncct, ncct = TRUE, stringsAsFactors = FALSE)

stics_q = read.csv(paste(folder, 'stics_q.csv', sep = ''), 
				   stringsAsFactors = FALSE)$doi
stics_q = unlist(regmatches(stics_q, gregexpr("'[^']*'", stics_q)))
stics_q = gsub("'", "", stics_q)
stics_q = data.frame(doi = stics_q, stics.q = TRUE, stringsAsFactors = FALSE)

stics_uq = read.csv(paste(folder, 'stics_uq.csv', sep = ''), 
					stringsAsFactors = FALSE)$doi
stics_uq = unlist(regmatches(stics_uq, gregexpr("'[^']*'", stics_uq)))
stics_uq = gsub("'", "", stics_uq)
stics_uq = data.frame(doi = stics_uq, stics.uq = TRUE, stringsAsFactors = FALSE)

dataf = full_join(ids_css, ids_ncct) %>% full_join(stics_q) %>% 
	full_join(stics_uq) %>% 
	filter(doi != '')
dataf[is.na(dataf)] = FALSE

db_names = c('EndNote', 'NCCT', 'STICS\n(Quoted)', 'STICS\n(Unquoted)')
```

Manual inspection of the STICS search results identified several apparent false matches; publications with no EPA-affiliated authors were discarded. 

```{r remove_nonepa}
# write.csv({dataf %>% filter(!ncct, !(stics.q & stics.uq)) %>% .[['doi']]},
# 			file = 'scraped pubs/poss nonepa.csv')
# stop()
nonepa = read.csv(paste(folder, 'poss nonepa.csv', sep = '')) %>% filter(!epa) %>% .[['doi']] %>% as.character
# dataf %>% filter(doi %in% nonepa) %>% select(stics.q, stics.uq, endnote) %>% table
dataf = dataf %>% filter(!(doi %in% nonepa))
```

```{r }
dataf %>% select(endnote:stics.uq) %>% summarize_each(funs = 'sum') %>% 
	kable(col.names = db_names, 
		  caption = 'Publications with DOIs found in each database/search')
```

Combining the results of all four database/searches yields a total of `r length(unique(dataf$doi))` distinct DOIs.  Both of the two STICS searches include a majority of these DOIs; the EndNote database contains slightly fewer than half; and the NCCT database contains just under 25% of all DOIs.  

```{r, fig.height = 2*fig.height, fig.cap = 'Distribution of individual papers across the four database/searches. **A**: Each paper is represented by a single row; a red cell indicates that the given paper is included in the given database/search. **B**: Each paper is represented by an unbroken line across the parallel coordinates. Y-axis indicates whether the given paper is included in the given database/search.'}
db_pubs_1 = ggplot(data = {dataf %>% melt(id.vars = 'doi', 
										  variable.name = 'database')},
	   aes(doi, database, fill = value)) +
	geom_tile() + 
	scale_x_discrete(labels = NULL) +
	scale_y_discrete(labels = db_names) +
	scale_fill_manual(values = c(NA, 'red'), guide = FALSE) + coord_flip()

db_pubs_2 = ggplot(data = {dataf %>% melt(id.vars = 'doi', 
										  variable.name = 'database',
										  value.name = 'included')}, 
	aes(x = database, y = included, group = doi)) + 
	geom_line(position = position_jitter(height = .5), alpha = .05) +
	scale_x_discrete(labels = db_names)

plot_grid(db_pubs_1, db_pubs_2, ncol = 1, labels = 'AUTO', align = 'v')
```

The plots above show the distribution of every individual paper across the four database/searches, as lit cells in a heatmap and as lines across parallel coordinates.  These plots suggest that the two STICS searches include almost exactly the same publications, and that there is relatively little overlap between NCCT and the other database/searches.  The tables below makes these same points quantitatively.  

```{r}
# dataf %>% select(endnote:stics.uq) %>% summary
dist = dataf %>% group_by(stics.q, stics.uq, endnote, ncct) %>% 
	summarize(n = n())
dist[dist == FALSE] = ''
dist[dist == TRUE] = 'X'
dist %>% kable(
		col.names = c('STICS (Quoted)', 'STICS (Unquoted)', 'EndNote', 
						'NCCT', 'n'), 
		align = c(rep('c', 4), 'r'),
		caption = 'Distribution of papers across the four database/searches')
dist = dataf %>% group_by(stics.q, stics.uq) %>% summarize(n = n())
dist[dist == FALSE] = ''
dist[dist == TRUE] = 'X'
dist %>% kable(
	col.names = c('STICS (Quoted)', 'STICS (Unquoted)', 'n'),
	align = c('c', 'c', 'r'),
	caption = 'Concordance between quoted and unquoted STICS search results')
```

```{r export, eval=FALSE}
write(toJSON(dataf$doi), paste(folder, 'combined dois.json', sep = ''))
## Clear environment
stop()
rm(list = ls())
pkgs = names(sessionInfo()$otherPkgs)
pkgs = paste('package:', pkgs, sep = "")
lapply(pkgs, detach, character.only = TRUE, unload = TRUE)
```

## Methods ##

Given the set of DOIs for the target papers, a Python script queries the Altmetrics API, retrieving data on every tweet that references one of the target papers.  The analysis then considers the number of tweets per paper, the number of CSS-related tweets per Twitter account, the estimated reach per paper and over time, and the delay (time between publication and first tweet) and lifespan (time between first and last tweet) for each Tweeted paper.  

```{r, eval = FALSE}
## Run the Python scripts with the Altmetrics queries
system2('python3', args = 'publications\\ data/scrape.py')
```

*[reference set]*

## Results ##

```{r setup_analysis} 
library(cowplot)
library(dplyr)
library(knitr)
	# opts_chunk$set(dev = 'tikz', 
	# 			   fig.height = 3, fig.width = 4, fig.align='center', 
	# 			   sanitize = TRUE,
	# 			   echo = FALSE,
	# 			   warning = FALSE, messages = FALSE
	# 			   )
library(lubridate)
library(rjson)
library(xtable)
# options(digits = 1, xtable.comment = FALSE)
```
```{r}
## Load all of the DOIs, even the ones that weren't in Altmetrics
infiles = 'publications data/scraped pubs/combined dois.json'
all_dois <- c()
for (infile in infiles) {
	all_dois <- c(all_dois, fromJSON(file = infile))
}
all_dois <- unique(all_dois)

## Load data, with mutations for R data types
folder = 'publications data/twitter/'
papers <- read.csv(paste(folder, 'metadata.csv', sep = ''), 
				   stringsAsFactors = FALSE) %>%
		mutate(n_tweets = as.integer(ifelse(is.na(n_tweets), 0, n_tweets)), 
			   first_seen = ymd_hms(first_seen), 
			   published = ymd_hms(published), 
			   year = floor_date(published, unit = 'year'))
tweets <- read.csv(paste(folder, 'tweets.csv', sep = '')) %>%
		mutate(timestamp = ymd_hms(timestamp))
tweeters <- read.csv(paste(folder, 'tweeters.csv', sep = ''))
```

A total of `r length(all_dois)` DOIs for CSS publications were identified.  Altmetrics returned responses for `r nrow(papers)` of these DOIs, of which 
`r {papers %>% filter(n_tweets > 0) %>% nrow}` 
(`r (1-ecdf(papers$n_tweets)(0))*100`%) 
had 1 or more tweets.  `r {papers %>% filter(n_tweets >= 10) %>% nrow}` papers had 10 or more tweets.  

```{r fig.cap = 'Histogram of tweets per paper'}
## Histogram of tweets per paper
ggplot(data = papers, aes(x = n_tweets)) + geom_bar(fill = 'blue') + 
	scale_x_log10(name = 'no. tweets', breaks = c(1, seq(10, 100, 20))) +
	ylab('no. papers')
## Scatterplot of n tweets vs. year
# ggplot(data = papers, aes(x = year, y = n_tweets)) + 
# 	geom_point()
```
```{r fig.cap = 'Number of tweets per month'}
## Plot tweets over time
tweets <- tweets %>% mutate(month = round_date(timestamp, unit = 'month'))
ggplot(data = tweets, aes(x = month)) + 
	#geom_line(stat = 'count', color = 'red') +
	geom_bar(fill = 'red') +
	geom_hline(yintercept = 0) +
	theme(axis.text.x=element_text(angle = 30, hjust = 1)) +
	ylab('no. tweets')
```
*[column names]*
```{r results = 'asis'}
## List of relatively highly-tweeted papers
papers %>% filter(n_tweets >= 10) %>% select(doi, title, n_tweets) %>%
	arrange(desc(n_tweets)) %>%
	xtable(align = 'llp{3in}r', 
		   caption = 'Highly-tweeted papers') %>% 
	print(include.rownames = FALSE)
```

Altmetrics returned a total of `r nrow(tweets)` tweets of CSS publications.  There is considerable variation in the number of tweets over time.  Tweets are made in `r tweets$account_loc %>% unique %>% length` different countries, though `r {tweets %>% filter(account_loc == '') %>% nrow} / nrow(tweets) * 100`% have no country information.  

```{r eval = FALSE}
## Table of countries with number of tweets and percentage of all tweets
tweets %>% group_by(account_loc) %>% 
	summarize(n_tweets = n()) %>% 
	mutate(tot_tweets = sum(n_tweets), perc_tweets = n_tweets / tot_tweets * 100) %>%
	arrange(desc(perc_tweets))
```
```{r fig.cap = 'Number of tweets per country, countries with at least 5 tweets'}
## Histogram of countries with at least 5 tweets
ggplot(data = {tweets %>% group_by(account_loc) %>% 
		summarize(n_tweets = n()) %>%
		mutate(location = reorder(account_loc, n_tweets)) %>%
		filter(n_tweets >= 5, account_loc != '')}, 
		aes(x = location, y = n_tweets, fill = location)) +
	geom_bar(stat = 'identity') +
	scale_fill_discrete(guide = FALSE) +
	coord_flip()
## Tweets over time, by location
##  Needs filters to be useful! 
#ggplot(data = tweets, aes(x = month, color = account_loc)) + geom_line(stat = 'count')
```

`r nrow(tweeters)` Twitter accounts made a total of `r sum(tweeters$n_tweets)` tweets of CSS papers.  `r {tweeters %>% filter(n_tweets == 1) %>% nrow}` accounts (`r ecdf(tweeters$n_tweets)(2) * 100`%) made only a single tweet of a CSS paper, while `r {tweeters %>% filter(n_tweets >= 5) %>% nrow}` accounts made 5 or more tweets.  

```{r fig.cap = 'Histogram of tweets per account'}
## Histogram of tweeters
ggplot(data = tweeters, aes(x = n_tweets)) + geom_bar() +
	scale_x_log10(breaks=c(1, seq(2, 18, by = 2)), name = 'no. tweets') +
	ylab('no. accounts')
```

*[column names]*
```{r results = 'asis'}
## List of relatively high number of tweeters
tweeters %>% filter(n_tweets >= 5) %>% 
	select(account, n_tweets, n_followers, location) %>%
	arrange(desc(n_tweets)) %>% 
	kable
```

Many of these relatively high-tweeting accounts promote recent publications in a scientific topic, in a journal, or of potential interest to members of a professional society.  


### Reach ###

In marketing, *reach* refers to the size of the potential audience.  The Altmetrics API provides the number of followers at the time of each individual tweet.  These follower counts can be used to estimate reach at the paper level and over time.  (Note that the followers for two given tweets can overlap, and so these are likely to be overestimates.)  Aggregated both ways, reach varies over more than two orders of magnitude.  

```{r fig.width = 2*fig.width, fig.caption = 'Kernel density estimates of estimated reach. **A** Reach per paper. **B** Reach per month.'}
## Estimate reach per paper
reach_by_paper <- tweets %>% group_by(paper_doi) %>% 
						summarize(reach = sum(account_followers))
## Kernel density estimate plot
reach_paper_kde = ggplot(data = reach_by_paper, aes(x = reach)) + 
	geom_density() +
	scale_x_log10(breaks = 10^(0:5))
## ECDF plot
# ggplot(data = reach_by_paper, aes(x = reach)) + stat_ecdf() +
# 	scale_x_log10(breaks = 10^(0:5))

## Estimate reach per month
reach_by_month <- tweets %>% group_by(month) %>%
						summarize(reach = sum(account_followers))
## Kernel density estimate plot
reach_month_kde = ggplot(data = reach_by_month, aes(x = reach)) + 
	geom_density() +
	scale_x_log10(breaks = 10^(0:5))
## ECDF plot
# ggplot(data = reach_by_month, aes(x = reach)) + stat_ecdf() + 
# 	scale_x_log10(breaks = 10^(0:5))
plot_grid(reach_paper_kde, reach_month_kde, labels = 'AUTO')
```
\

```{r eval = FALSE}
## Reach by month, plotted over time
ggplot(data = reach_by_month, aes(x = month, y = reach)) +
	#geom_line(color = 'red') +
	geom_bar(fill = 'blue', stat = 'identity', position = 'identity') +
	geom_hline(yintercept = 0) +
	scale_y_log10(breaks = 10^(0:5)) +
	theme(axis.text.x=element_text(angle = 30, hjust = 1))
```


### Delay and Lifespan ###

*[details for every plot below]*

```{r}
## Identify the earliest and latest tweet for each paper
##  and calculate delay and lifespan
papers <- left_join(papers, 
				  {tweets %>% group_by(paper_doi) %>% 
				  		summarize(first_tweet = min(timestamp), 
				  				  last_tweet = max(timestamp))}, 
				  by = c('doi' = 'paper_doi')) %>%
				mutate(delay = difftime(first_tweet, published, 
										units = 'days'),
					   lifespan = difftime(last_tweet, first_tweet, 
					   					units = 'days')
					   )
```

*Delay* can be defined as the time between publication date (as recorded in the Altmetrics metadata) and the first tweet.  Delay had a mean of `r mean(papers$delay, na.rm = T)` days and median of `r median(papers$delay, na.rm = T)` days, with an interquartile range of `r IQR(papers$delay, na.rm = T)` days.  `r ecdf(papers$delay)(7) * 100`% of papers had a delay of less than 7 days; notably, `r ecdf(papers$delay)(0) * 100`% of papers had a negative delay, indicating that the paper was first tweeted before it was officially published.  No relationship was identified between delay and the total number of tweets received by a paper.  

```{r delay}
## KDE of delay
ggplot(data = papers, aes(x = delay)) + 
	geom_density(alpha = .5, position = 'stack') +
	geom_rug() +
	xlab('delay (days)')
	#coord_cartesian(xlim = c(0, 28))

## Number of tweets vs. delay
xmin <- 0; xmax <- 14*7; ymin <- 0; ymax <- 20
tweets_delay_plot <- ggplot(data = papers,
							aes(x = delay, y = n_tweets)) +
	geom_point(position = 'jitter') +
	geom_rect(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, 
				  fill = NA, linetype = 'dashed', color = 'gray', 
				  alpha = .05)
tweets_delay_all <- tweets_delay_plot + 
		stat_smooth(method = 'lm', alpha = .1) +
		coord_cartesian(ylim = c(0, 80))
tweets_delay_zoom <- tweets_delay_plot + 
	stat_smooth(method = 'lm', alpha = .1) + 
	coord_cartesian(xlim = c(xmin, xmax), ylim = c(ymin, ymax))
tweets_delay_all; tweets_delay_zoom
#plot_grid(tweets_delay_all, tweets_delay_zoom, nrow = 2)
## There's no evidence of a relationship here
lm(data = papers, n_tweets ~ delay) %>% summary

## Table of week vs. percentile
data.frame(week = seq(0, 4)) %>% 
	mutate(percentile = ecdf(papers$delay)(week*7)*100) %>%
	kable(caption = 'Delay, cumulative percentiles, by week')
## Table of percentile vs. day
# data.frame(decimal = seq(.10, .90, by = .10)) %>%
# 	transmute(percentile = decimal * 100, 
# 				days = as.numeric(quantile(papers$delay, 
# 									  probs = decimal, na.rm = TRUE))) %>%
# 	kable
```

Similarly, *lifespan* can be defined as the time between the first and last tweet.  Lifespan had a mean of `r mean(papers$lifespan, na.rm = T)` days and median of `r median(papers$lifespan, na.rm = T)*24` *hours*, with an interquartile range of `r IQR(papers$lifespan, na.rm = T)` days.  `r ecdf(papers$lifespan)(7) * 100`% of papers had a lifespan of less than 7 days.  No relationship was identified between lifespan and the total number of tweets received by a paper. 

```{r lifespan}
## KDE of lifespan
ggplot(data = papers, aes(x = lifespan)) + 
	geom_density(alpha = .5, position = 'stack') +
	geom_rug() +
	xlab('lifespan (days)')
#	coord_cartesian(xlim = c(0, 100)) + 

## Number of tweets vs. lifespan
xmin <- 0; xmax <- 14*7; ymin <- 0; ymax <- 20
tweets_span_plot <- ggplot(data = papers,
							aes(x = lifespan, y = n_tweets)) +
		geom_point(position = 'jitter') +
		geom_rect(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, 
				  fill = NA, linetype = 'dashed', color = 'gray', 
				  alpha = .05) 
tweets_span_all <- tweets_span_plot + 
		stat_smooth(method = 'lm', alpha = .1)
tweets_span_zoom <- tweets_span_plot + 
	stat_smooth(method = 'lm', alpha = .1) + 
	coord_cartesian(xlim = c(xmin, xmax), ylim = c(ymin, ymax))
tweets_span_all; tweets_span_zoom
#plot_grid(tweets_span_all, tweets_span_zoom, nrow = 2)
## There's no evidence of a relationship here, either
lm(data = papers, n_tweets ~ lifespan) %>% summary

## Cumulative percentile tables
data.frame(week = seq(0, 14, by = 2)) %>% 
	mutate(percentile = ecdf(papers$lifespan)(week*7) * 100) %>%
	kable(caption = 'Lifespan, cumulative percentiles, by week')
# data.frame(decimal = seq(.10, .90, by = .20)) %>%
# 	transmute(percentile = decimal * 100, 
# 			  days = as.numeric(quantile(papers$lifespan, 
# 			  						   probs = decimal, na.rm = TRUE))) %>%
# 	kable
```

Finally, there is no observed relationship between delay and lifespan.  

```{r}
## Delay vs. lifespan
xmin <- 0; xmax <- 20*7; ymin <- 0; ymax <- 500
delay_span_plot <- ggplot(data = papers, aes(delay, lifespan)) + 
		geom_point(position = 'jitter') +
		geom_rect(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, 
				  fill = NA, linetype = 'dashed', color = 'gray', 
				  alpha = .05) + 
		stat_smooth(method = 'lm')
delay_span_all <- delay_span_plot
delay_span_zoom <- delay_span_plot + 
	coord_cartesian(xlim = c(xmin, xmax), ylim = c(ymin, ymax))
delay_span_all; delay_span_zoom
#lm(data = papers, as.numeric(lifespan) ~ as.numeric(delay)) %>% summary
```








